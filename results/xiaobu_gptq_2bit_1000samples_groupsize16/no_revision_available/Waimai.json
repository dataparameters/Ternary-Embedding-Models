{
  "dataset_revision": "339287def212450dcaa9df8c22bf93e9980c7023",
  "evaluation_time": 10.766108512878418,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.18",
  "scores": {
    "test": [
      {
        "accuracy": 0.8797,
        "ap": 0.7252000943033905,
        "ap_weighted": 0.7252000943033905,
        "f1": 0.8651551795644832,
        "f1_weighted": 0.8806115324466244,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.8797,
        "scores_per_experiment": [
          {
            "accuracy": 0.899,
            "ap": 0.7624311270125224,
            "ap_weighted": 0.7624311270125224,
            "f1": 0.886572802853424,
            "f1_weighted": 0.8997133436428548
          },
          {
            "accuracy": 0.882,
            "ap": 0.7288792899408284,
            "ap_weighted": 0.7288792899408284,
            "f1": 0.8655270655270655,
            "f1_weighted": 0.882
          },
          {
            "accuracy": 0.873,
            "ap": 0.7110087912087912,
            "ap_weighted": 0.7110087912087912,
            "f1": 0.858001397624039,
            "f1_weighted": 0.8741537386443047
          },
          {
            "accuracy": 0.875,
            "ap": 0.71565528589058,
            "ap_weighted": 0.71565528589058,
            "f1": 0.8625465829630339,
            "f1_weighted": 0.8770273004478782
          },
          {
            "accuracy": 0.852,
            "ap": 0.6761645569620254,
            "ap_weighted": 0.6761645569620254,
            "f1": 0.8394097222222222,
            "f1_weighted": 0.8551475694444445
          },
          {
            "accuracy": 0.89,
            "ap": 0.7465349763505104,
            "ap_weighted": 0.7465349763505104,
            "f1": 0.8729856681646659,
            "f1_weighted": 0.8892562040727722
          },
          {
            "accuracy": 0.892,
            "ap": 0.7488944922147339,
            "ap_weighted": 0.7488944922147339,
            "f1": 0.8775043554006968,
            "f1_weighted": 0.8922528310104529
          },
          {
            "accuracy": 0.885,
            "ap": 0.7342743441529569,
            "ap_weighted": 0.7342743441529569,
            "f1": 0.8710413912278989,
            "f1_weighted": 0.8858909750280063
          },
          {
            "accuracy": 0.877,
            "ap": 0.7187711069418388,
            "ap_weighted": 0.7187711069418388,
            "f1": 0.8601622799687582,
            "f1_weighted": 0.8771455710665526
          },
          {
            "accuracy": 0.872,
            "ap": 0.7093869723591172,
            "ap_weighted": 0.7093869723591172,
            "f1": 0.8578005296930269,
            "f1_weighted": 0.8735277911089782
          }
        ]
      }
    ]
  },
  "task_name": "Waimai"
}