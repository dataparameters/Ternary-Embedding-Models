{
  "dataset_revision": "339287def212450dcaa9df8c22bf93e9980c7023",
  "evaluation_time": 3.0451600551605225,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.12",
  "scores": {
    "test": [
      {
        "accuracy": 0.8619,
        "ap": 0.6916016629543033,
        "ap_weighted": 0.6916016629543033,
        "f1": 0.8465946646369608,
        "f1_weighted": 0.8635113290203732,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.8619,
        "scores_per_experiment": [
          {
            "accuracy": 0.875,
            "ap": 0.7149688850475369,
            "ap_weighted": 0.7149688850475369,
            "f1": 0.8608388190670857,
            "f1_weighted": 0.8763761649182457
          },
          {
            "accuracy": 0.854,
            "ap": 0.6763509482207543,
            "ap_weighted": 0.6763509482207543,
            "f1": 0.8380304502753482,
            "f1_weighted": 0.8558309037900874
          },
          {
            "accuracy": 0.863,
            "ap": 0.6926752136752137,
            "ap_weighted": 0.6926752136752137,
            "f1": 0.8479087452471483,
            "f1_weighted": 0.8646768060836502
          },
          {
            "accuracy": 0.858,
            "ap": 0.6854143402289616,
            "ap_weighted": 0.6854143402289616,
            "f1": 0.8447639537527768,
            "f1_weighted": 0.8606290776792431
          },
          {
            "accuracy": 0.839,
            "ap": 0.6555740810913224,
            "ap_weighted": 0.6555740810913224,
            "f1": 0.8264411047832184,
            "f1_weighted": 0.8427816747678785
          },
          {
            "accuracy": 0.88,
            "ap": 0.7249295070254823,
            "ap_weighted": 0.7249295070254823,
            "f1": 0.8630287091825554,
            "f1_weighted": 0.8799035722112646
          },
          {
            "accuracy": 0.872,
            "ap": 0.7089083276605401,
            "ap_weighted": 0.7089083276605401,
            "f1": 0.8557102662145588,
            "f1_weighted": 0.8726787389077267
          },
          {
            "accuracy": 0.854,
            "ap": 0.6763509482207543,
            "ap_weighted": 0.6763509482207543,
            "f1": 0.8380304502753482,
            "f1_weighted": 0.8558309037900874
          },
          {
            "accuracy": 0.866,
            "ap": 0.6973950533242569,
            "ap_weighted": 0.6973950533242569,
            "f1": 0.8489466849433662,
            "f1_weighted": 0.8667105547940264
          },
          {
            "accuracy": 0.858,
            "ap": 0.6834493250482109,
            "ap_weighted": 0.6834493250482109,
            "f1": 0.8422474626282017,
            "f1_weighted": 0.8596948932615226
          }
        ]
      }
    ]
  },
  "task_name": "Waimai"
}