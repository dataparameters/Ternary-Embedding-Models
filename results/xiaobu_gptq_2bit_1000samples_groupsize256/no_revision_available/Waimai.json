{
  "dataset_revision": "339287def212450dcaa9df8c22bf93e9980c7023",
  "evaluation_time": 11.231117963790894,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.18",
  "scores": {
    "test": [
      {
        "accuracy": 0.8587,
        "ap": 0.6862147554614246,
        "ap_weighted": 0.6862147554614246,
        "f1": 0.8424528566930863,
        "f1_weighted": 0.8600527980522811,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.8587,
        "scores_per_experiment": [
          {
            "accuracy": 0.872,
            "ap": 0.709185007626934,
            "ap_weighted": 0.709185007626934,
            "f1": 0.8571932220333007,
            "f1_weighted": 0.8732875459101478
          },
          {
            "accuracy": 0.867,
            "ap": 0.6991463414634147,
            "ap_weighted": 0.6991463414634147,
            "f1": 0.848793359641015,
            "f1_weighted": 0.8671574061126138
          },
          {
            "accuracy": 0.86,
            "ap": 0.6872354570637119,
            "ap_weighted": 0.6872354570637119,
            "f1": 0.8446867331407448,
            "f1_weighted": 0.861755661168577
          },
          {
            "accuracy": 0.86,
            "ap": 0.686309921962096,
            "ap_weighted": 0.686309921962096,
            "f1": 0.842890809112333,
            "f1_weighted": 0.8610369206598585
          },
          {
            "accuracy": 0.83,
            "ap": 0.6452192218866584,
            "ap_weighted": 0.6452192218866584,
            "f1": 0.8194247936131611,
            "f1_weighted": 0.8347195135941264
          },
          {
            "accuracy": 0.877,
            "ap": 0.7203278265358802,
            "ap_weighted": 0.7203278265358802,
            "f1": 0.856621799781086,
            "f1_weighted": 0.8755405532999717
          },
          {
            "accuracy": 0.861,
            "ap": 0.6881305903398928,
            "ap_weighted": 0.6881305903398928,
            "f1": 0.8438972237289697,
            "f1_weighted": 0.8619817303599685
          },
          {
            "accuracy": 0.853,
            "ap": 0.6751521739130435,
            "ap_weighted": 0.6751521739130435,
            "f1": 0.8377037397695393,
            "f1_weighted": 0.8551424729313023
          },
          {
            "accuracy": 0.859,
            "ap": 0.6837842401500938,
            "ap_weighted": 0.6837842401500938,
            "f1": 0.8396982233788204,
            "f1_weighted": 0.8591668741494627
          },
          {
            "accuracy": 0.848,
            "ap": 0.6676567736725217,
            "ap_weighted": 0.6676567736725217,
            "f1": 0.833618662731894,
            "f1_weighted": 0.8507393023367821
          }
        ]
      }
    ]
  },
  "task_name": "Waimai"
}