{
  "dataset_revision": "339287def212450dcaa9df8c22bf93e9980c7023",
  "evaluation_time": 11.203474283218384,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.18",
  "scores": {
    "test": [
      {
        "accuracy": 0.8521999999999998,
        "ap": 0.6745000188198463,
        "ap_weighted": 0.6745000188198463,
        "f1": 0.8354655485337886,
        "f1_weighted": 0.853748841444433,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.8521999999999998,
        "scores_per_experiment": [
          {
            "accuracy": 0.863,
            "ap": 0.6920486295313881,
            "ap_weighted": 0.6920486295313881,
            "f1": 0.8465967431480812,
            "f1_weighted": 0.8641537458947832
          },
          {
            "accuracy": 0.842,
            "ap": 0.6544312026002167,
            "ap_weighted": 0.6544312026002167,
            "f1": 0.8239750445632799,
            "f1_weighted": 0.8436898395721925
          },
          {
            "accuracy": 0.855,
            "ap": 0.6783930684699916,
            "ap_weighted": 0.6783930684699916,
            "f1": 0.8394737395644092,
            "f1_weighted": 0.8569470230128232
          },
          {
            "accuracy": 0.857,
            "ap": 0.6806851520572451,
            "ap_weighted": 0.6806851520572451,
            "f1": 0.8394050575053429,
            "f1_weighted": 0.858009981593349
          },
          {
            "accuracy": 0.816,
            "ap": 0.6207297595006425,
            "ap_weighted": 0.6207297595006425,
            "f1": 0.8030956783781933,
            "f1_weighted": 0.8207383055955072
          },
          {
            "accuracy": 0.875,
            "ap": 0.7150662796323174,
            "ap_weighted": 0.7150662796323174,
            "f1": 0.8567418981813097,
            "f1_weighted": 0.874641998003555
          },
          {
            "accuracy": 0.864,
            "ap": 0.6933076923076924,
            "ap_weighted": 0.6933076923076924,
            "f1": 0.84375,
            "f1_weighted": 0.8634375
          },
          {
            "accuracy": 0.835,
            "ap": 0.6463687549563839,
            "ap_weighted": 0.6463687549563839,
            "f1": 0.8201891610026253,
            "f1_weighted": 0.8382511597799115
          },
          {
            "accuracy": 0.856,
            "ap": 0.678891861761427,
            "ap_weighted": 0.678891861761427,
            "f1": 0.8384019750869711,
            "f1_weighted": 0.8570665469644261
          },
          {
            "accuracy": 0.859,
            "ap": 0.6850777873811581,
            "ap_weighted": 0.6850777873811581,
            "f1": 0.8430261879076726,
            "f1_weighted": 0.860552314027781
          }
        ]
      }
    ]
  },
  "task_name": "Waimai"
}