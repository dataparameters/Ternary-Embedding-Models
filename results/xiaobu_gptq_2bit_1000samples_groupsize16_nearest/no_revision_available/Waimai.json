{
  "dataset_revision": "339287def212450dcaa9df8c22bf93e9980c7023",
  "evaluation_time": 11.344847917556763,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.18",
  "scores": {
    "test": [
      {
        "accuracy": 0.8739000000000001,
        "ap": 0.7144199442530261,
        "ap_weighted": 0.7144199442530261,
        "f1": 0.8590823440700046,
        "f1_weighted": 0.8750121168511971,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.8739000000000001,
        "scores_per_experiment": [
          {
            "accuracy": 0.888,
            "ap": 0.7401895366880957,
            "ap_weighted": 0.7401895366880957,
            "f1": 0.8744979919678715,
            "f1_weighted": 0.8889056224899597
          },
          {
            "accuracy": 0.872,
            "ap": 0.7089325443786982,
            "ap_weighted": 0.7089325443786982,
            "f1": 0.8541310541310541,
            "f1_weighted": 0.872
          },
          {
            "accuracy": 0.868,
            "ap": 0.7020879423606696,
            "ap_weighted": 0.7020879423606696,
            "f1": 0.85376488939308,
            "f1_weighted": 0.8697337634713557
          },
          {
            "accuracy": 0.88,
            "ap": 0.724585601028498,
            "ap_weighted": 0.724585601028498,
            "f1": 0.8666879965872127,
            "f1_weighted": 0.881432304164667
          },
          {
            "accuracy": 0.843,
            "ap": 0.6625203619909503,
            "ap_weighted": 0.6625203619909503,
            "f1": 0.8309484866659274,
            "f1_weighted": 0.8467463505869964
          },
          {
            "accuracy": 0.894,
            "ap": 0.756029900332226,
            "ap_weighted": 0.756029900332226,
            "f1": 0.8767619552529635,
            "f1_weighted": 0.8928938153103506
          },
          {
            "accuracy": 0.88,
            "ap": 0.724540972380735,
            "ap_weighted": 0.724540972380735,
            "f1": 0.8645225095850324,
            "f1_weighted": 0.8805494967011229
          },
          {
            "accuracy": 0.873,
            "ap": 0.7109279679857715,
            "ap_weighted": 0.7109279679857715,
            "f1": 0.8575848407473319,
            "f1_weighted": 0.8739839463352767
          },
          {
            "accuracy": 0.876,
            "ap": 0.7166923076923077,
            "ap_weighted": 0.7166923076923077,
            "f1": 0.8597919493441881,
            "f1_weighted": 0.8764767073722298
          },
          {
            "accuracy": 0.865,
            "ap": 0.6976923076923077,
            "ap_weighted": 0.6976923076923077,
            "f1": 0.8521317670253841,
            "f1_weighted": 0.8673991620800132
          }
        ]
      }
    ]
  },
  "task_name": "Waimai"
}