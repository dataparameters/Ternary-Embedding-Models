{
  "dataset_revision": "339287def212450dcaa9df8c22bf93e9980c7023",
  "evaluation_time": 11.252227783203125,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.18",
  "scores": {
    "test": [
      {
        "accuracy": 0.8447000000000001,
        "ap": 0.6616124908408271,
        "ap_weighted": 0.6616124908408271,
        "f1": 0.8269640803648685,
        "f1_weighted": 0.84622502009241,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.8447000000000001,
        "scores_per_experiment": [
          {
            "accuracy": 0.857,
            "ap": 0.6812850934376358,
            "ap_weighted": 0.6812850934376358,
            "f1": 0.8405724230427478,
            "f1_weighted": 0.858484111313895
          },
          {
            "accuracy": 0.847,
            "ap": 0.6607078870496592,
            "ap_weighted": 0.6607078870496592,
            "f1": 0.8243638354805716,
            "f1_weighted": 0.8464325195524377
          },
          {
            "accuracy": 0.851,
            "ap": 0.6688205128205129,
            "ap_weighted": 0.6688205128205129,
            "f1": 0.8308692074122421,
            "f1_weighted": 0.8512917506172138
          },
          {
            "accuracy": 0.837,
            "ap": 0.6479008638420403,
            "ap_weighted": 0.6479008638420403,
            "f1": 0.8207607441837961,
            "f1_weighted": 0.8396435997840332
          },
          {
            "accuracy": 0.808,
            "ap": 0.6107244333392825,
            "ap_weighted": 0.6107244333392825,
            "f1": 0.7958454550094421,
            "f1_weighted": 0.8132802531516358
          },
          {
            "accuracy": 0.87,
            "ap": 0.7057145412726807,
            "ap_weighted": 0.7057145412726807,
            "f1": 0.8488590017253326,
            "f1_weighted": 0.8686433583994866
          },
          {
            "accuracy": 0.837,
            "ap": 0.6464594135146622,
            "ap_weighted": 0.6464594135146622,
            "f1": 0.8192966760565878,
            "f1_weighted": 0.8390927251945887
          },
          {
            "accuracy": 0.852,
            "ap": 0.671966469428008,
            "ap_weighted": 0.671966469428008,
            "f1": 0.8346413057080033,
            "f1_weighted": 0.8533929816407158
          },
          {
            "accuracy": 0.867,
            "ap": 0.6992086596038692,
            "ap_weighted": 0.6992086596038692,
            "f1": 0.8494996712755978,
            "f1_weighted": 0.8674618855088552
          },
          {
            "accuracy": 0.821,
            "ap": 0.6233370340999207,
            "ap_weighted": 0.6233370340999207,
            "f1": 0.8049324837543632,
            "f1_weighted": 0.8245270157612374
          }
        ]
      }
    ]
  },
  "task_name": "Waimai"
}